{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this code introduces you to machine learning training and inference (predictions) in Python on AWS\n",
    "\n",
    "#start a line with '!' to write to the command line instead. \n",
    "#This allows you to install packages to the EC2 instance from within jupyter\n",
    "!pip install seaborn\n",
    "\n",
    "#import the packages that you installed\n",
    "import pandas as pd\n",
    "import seaborn.apionly as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#load a default seaborn dataset, display simple stats about data size, and then print the data's head\n",
    "df = pd.DataFrame(sns.load_dataset('iris'))\n",
    "print 'shape of the data frame'+str(df.shape)\n",
    "print df.groupby(['species']).size()\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showoff some of what seaborn can do\n",
    "sns.pairplot(df, hue=\"species\", diag_kind=\"kde\",markers=['o','x','+'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's group setosa and verginica together for the sake of this machine learning exercise\n",
    "df['y']= np.where(df['species']=='versicolor', 1,0)\n",
    "print df.groupby(['y']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test\n",
    "X=df.drop('species',1).drop('y',1)\n",
    "y=df['y']\n",
    "RANDOM_STATE=0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=RANDOM_STATE)\n",
    "print ('the number in training set: '+str(len(X_train)))\n",
    "print ('the number in test set: '+str(len(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized search for model selection\n",
    "#clf = RandomForestClassifier(n_estimators=50)\n",
    "clf = DecisionTreeClassifier()\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=5):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean OOB score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 4),\n",
    "              \"min_samples_split\": sp_randint(2, 5),\n",
    "              \"min_samples_leaf\": sp_randint(1, 5),\n",
    "              #\"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 30\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "#this might take a minute to run\n",
    "print(\"RandomizedSearchCV examined %d candidate parameter settings.\" % (n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.5 Train the random forest according to the best paramater setting given above. Show model outputs.\n",
    "\n",
    "#YOUR HOMEWORK IS TO SWITCH RANDOM FOREST CLASSIFIED WITH ANOTHER CLASSIFIER FROM THE SCIKIT LEARN API\n",
    "#http://scikit-learn.org/stable/\n",
    "#clf = RandomForestClassifier(n_estimators=50, oob_score=True, max_features=3, criterion='gini',bootstrap=True,min_samples_split=2,min_samples_leaf=4,max_depth=3)\n",
    "clf = DecisionTreeClassifier(max_features=3,min_samples_split=2,min_samples_leaf=4,max_depth=3)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "names = X.columns\n",
    "items=sorted(zip(map(lambda r: round(r, 3), clf.feature_importances_), names), reverse=True)\n",
    "\n",
    "print ('\\nfeature importance ')\n",
    "for r in items:\n",
    "    print(str(round(r[0],4))+' '+r[1])\n",
    "    \n",
    "y_pred=clf.predict(X_test)\n",
    "y_scores=clf.predict_proba(X_test)\n",
    "print ('\\nconfusion matrix')\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "print('\\nauc score '+str(auc(false_positive_rate, true_positive_rate)))\n",
    "\n",
    "#show a tradeoff curve for precision vs recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.7 ROC Curve\n",
    "fpr, tpr , threshold = roc_curve(y_test,clf.predict_proba(X_test)[:,1])\n",
    "roc_auc=auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "#Specificity: How many negatives were identified as negative.\n",
    "plt.xlabel('False Positive Rate (Specificity)')\n",
    "#Recall: How many positives were identified as positive.\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to save your model to disk and then to s3\n",
    "import pickle\n",
    "local_path = \"/home/ec2-user\" # temp path to export your model\n",
    "bucket_name = \"mybucketsashank\" # s3 key to save your network to\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'decision_tree_finalized_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "#you should now see your finalized_model.sav in the file path\n",
    "#the ls command prints the contents of this notebook's root folder\n",
    "!ls\n",
    " \n",
    "# Upload to S3\n",
    "#TO GET THIS WORKING, YOU MUST ASSIGN AN ADMIN ROLE TO YOUR EC2 INSTANCE\n",
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket_name).put_object(Key=filename, Body=open(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some time later...\n",
    " \n",
    "# load the model from s3 and make new predictions\n",
    "s3.Bucket(bucket_name).download_file(filename, 'decision_tree_finalized_model.sav')\n",
    "loaded_model = pickle.load(open('decision_tree_finalized_model.sav', 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that you can now call this model saved in S3 from ANY internet connected location\n",
    "\n",
    "#now push your notebook to your github page and submit the link as your homework\n",
    "#instructions: https://www.howtoforge.com/tutorial/install-git-and-github-on-ubuntu-14.04/\n",
    "#identify your username\n",
    "!git config --global user.name \"spandem\"\n",
    "#make a local git repository\n",
    "!git init DecisionTree\n",
    "#navigate to the repo\n",
    "cd /home/ec2-user/DecisionTree\n",
    "#create a README\n",
    "!echo \"this is my README file\" >>README\n",
    "#move your notebook into the git folder (you will need to re-enter your notebook interface after moving the file)\n",
    "!mv /home/ec2-user/ADS_Class/intro_to_python_data_science_on_aws.ipynb /home/ec2-user/DecisionTree/\n",
    "#make a new repo for yourself within your github.com account\n",
    "#add the files that you just made to tracking\n",
    "!git add intro_to_python_data_science_on_aws.ipynb\n",
    "!git add README\n",
    "#then remote add the github repo that you just made\n",
    "!git remote add origin https://github.com/spandem/DecisionTree.git\n",
    "#commit files\n",
    "!git commit -m \"initial version\"\n",
    "#then push your files to the git account\n",
    "!git push origin master\n",
    "#you will be prompted to enter your security credentials\n",
    "\n",
    "\n",
    "#if this isn't working for you, another option is to download the file to your local machine using the following:\n",
    "#sudo scp -r -i 'yourkeypair.pem' ubuntu@publicDNS:/home/ubuntu/intro_to_python_data_science_on_aws.ipynb localpath\n",
    "#windows people should use something like FileZilla to transfer files from a linux EC2 server to a local windows machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spandem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
